{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "df_titanic = sns.load_dataset('titanic')\n",
    "df_titanic.rename(columns={'fare': 'target'}, inplace=True)\n",
    "df_titanic_num = df_titanic.select_dtypes(include=[np.number])\n",
    "\n",
    "def generateMissingValues(df, missingRate):\n",
    "    df = df.mask(np.random.random(df.shape) < missingRate)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation and Basic Pipelines\n",
    "\n",
    "## Imputation\n",
    "\n",
    "Until this point, if we are missing data in our dataset, we have simply dropped the rows with missing data. However, this is not always the best approach. In real world data analysis, we often need to deal with missing data without just losing everything. For example, if your company does a survey of customers to collect data, it is likely that at least some of the customers will not answer all the questions. Just dropping an entire row of data if one question is missing can be costly - getting this data takes effort and costs money, so we want to use it as much as possible.\n",
    "\n",
    "Imputation is the process of replacing missing data with substituted values, or deleting it. There are several approaches, from dead simple to complex and advanced. \n",
    "\n",
    "### Simple Imputation\n",
    "\n",
    "The tool that we can use to do imputation is the sklearn `SimpleImputer`. This works fairly simply, it takes in a dataset and replaces all missing values with a specified value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "We'll load some data, and generate some missing values to play with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch embarked  class    who  \\\n",
       "0       0.0     3.0    male  22.0    1.0    0.0        S  Third    man   \n",
       "1       1.0     1.0  female   NaN    1.0    0.0      NaN  First  woman   \n",
       "2       1.0     3.0  female  26.0    0.0    0.0        S  Third  woman   \n",
       "3       1.0     1.0  female  35.0    1.0    0.0        S  First    NaN   \n",
       "4       0.0     NaN    male  35.0    0.0    0.0        S  Third    man   \n",
       "\n",
       "  adult_male deck  embark_town alive  alone   target  \n",
       "0       True  NaN  Southampton    no    NaN   7.2500  \n",
       "1      False    C    Cherbourg   yes  False  71.2833  \n",
       "2      False  NaN          NaN   yes   True   7.9250  \n",
       "3      False    C  Southampton   NaN  False  53.1000  \n",
       "4       True  NaN  Southampton    no   True   8.0500  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset(\"titanic\")\n",
    "df.rename(columns={'fare': 'target'}, inplace=True)\n",
    "y = df[\"target\"]\n",
    "df = generateMissingValues(df.drop(columns=[\"target\"]), 0.1)\n",
    "df[\"target\"] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removal\n",
    "\n",
    "The most simple version of imputation is to just remove the rows with missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>263.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>B</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>61.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>D</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>77.2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>B</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>79.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>66.6000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch embarked  class    who  \\\n",
       "27        0.0     1.0    male  19.0    3.0    2.0        S  First    man   \n",
       "54        0.0     1.0    male  65.0    0.0    1.0        C  First    man   \n",
       "102       0.0     1.0    male  21.0    0.0    1.0        S  First    man   \n",
       "139       0.0     1.0    male  24.0    0.0    0.0        C  First    man   \n",
       "151       1.0     1.0  female  22.0    1.0    0.0        S  First  woman   \n",
       "\n",
       "    adult_male deck  embark_town alive  alone    target  \n",
       "27        True    C  Southampton    no  False  263.0000  \n",
       "54        True    B    Cherbourg    no  False   61.9792  \n",
       "102       True    D  Southampton    no  False   77.2875  \n",
       "139       True    B    Cherbourg    no   True   79.2000  \n",
       "151      False    C  Southampton   yes  False   66.6000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_removed = df.dropna()\n",
    "print(df_removed.shape)\n",
    "df_removed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Imputation\n",
    "\n",
    "When we have numerical data, we can replace missing values with the mean, median, or mode of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 6)\n",
      "survived    102\n",
      "pclass       65\n",
      "age         244\n",
      "sibsp        87\n",
      "parch        84\n",
      "target        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch   target\n",
       "0       0.0     3.0  22.0    1.0    0.0   7.2500\n",
       "1       1.0     1.0   NaN    1.0    0.0  71.2833\n",
       "2       1.0     3.0  26.0    0.0    0.0   7.9250\n",
       "3       1.0     1.0  35.0    1.0    0.0  53.1000\n",
       "4       0.0     NaN  35.0    0.0    0.0   8.0500"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = df.select_dtypes(include=[np.number]).columns\n",
    "numeric_features = df[numeric_features]\n",
    "print(numeric_features.shape)\n",
    "print(numeric_features.isna().sum())\n",
    "numeric_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 6)\n",
      "survived    0\n",
      "pclass      0\n",
      "age         0\n",
      "sibsp       0\n",
      "parch       0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch   target\n",
       "0       0.0     3.0  22.0    1.0    0.0   7.2500\n",
       "1       1.0     1.0  28.0    1.0    0.0  71.2833\n",
       "2       1.0     3.0  26.0    0.0    0.0   7.9250\n",
       "3       1.0     1.0  35.0    1.0    0.0  53.1000\n",
       "4       0.0     3.0  35.0    0.0    0.0   8.0500"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "median_df = imputer.fit_transform(numeric_features)\n",
    "median_df = pd.DataFrame(median_df, columns=numeric_features.columns)\n",
    "print(median_df.shape)\n",
    "print(median_df.isna().sum())\n",
    "median_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean vs Median\n",
    "\n",
    "For most numerical values, we use either the mean or the median if we are inserting a value, at least for simple imputation. The distribution of a column can offer some guidance on which to use. \n",
    "\n",
    "One common example of this is with income/wealth related data, where we have a distribution that tends to be very skewed. If using skewed data, the median can often be a better choice than the mean for imputation, as the mean can be substantially impacted by some very large or very small values. This is very situation dependent, and you should always consider the specifics of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Imputation\n",
    "\n",
    "When we have categorical data, we can replace missing values with the most common category, or a new category that represents missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 7)\n",
      "sex             96\n",
      "embarked        96\n",
      "who            101\n",
      "adult_male      89\n",
      "embark_town    101\n",
      "alive           88\n",
      "alone          108\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p1/m8wtcgx57417hx9d_r110ctw0000gn/T/ipykernel_20126/1676507992.py:1: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  categorical_features = df.select_dtypes(include=[np.object]).columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>embarked</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex embarked    who adult_male  embark_town alive  alone\n",
       "0    male        S    man       True  Southampton    no    NaN\n",
       "1  female      NaN  woman      False    Cherbourg   yes  False\n",
       "2  female        S  woman      False          NaN   yes   True\n",
       "3  female        S    NaN      False  Southampton   NaN  False\n",
       "4    male        S    man       True  Southampton    no   True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = df.select_dtypes(include=[np.object]).columns\n",
    "categorical_features = df[categorical_features]\n",
    "print(categorical_features.shape)\n",
    "print(categorical_features.isna().sum())\n",
    "categorical_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 7)\n",
      "sex            0\n",
      "embarked       0\n",
      "who            0\n",
      "adult_male     0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>embarked</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>man</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex embarked    who adult_male  embark_town alive  alone\n",
       "0    male        S    man       True  Southampton    no   True\n",
       "1  female        S  woman      False    Cherbourg   yes  False\n",
       "2  female        S  woman      False  Southampton   yes   True\n",
       "3  female        S    man      False  Southampton    no  False\n",
       "4    male        S    man       True  Southampton    no   True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "most_frequent_df = cat_imputer.fit_transform(categorical_features)\n",
    "most_frequent_df = pd.DataFrame(most_frequent_df, columns=categorical_features.columns)\n",
    "print(most_frequent_df.shape)\n",
    "print(most_frequent_df.isna().sum())\n",
    "most_frequent_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation Considerations\n",
    "\n",
    "\n",
    "#### Removing vs Imputing\n",
    "\n",
    "One common consideration if a feature has many missing values is whether to remove the feature or impute the missing values. If a feature has many missing values, it may not be useful for analysis. However, if the feature is important, it may be better to impute the missing values. There is a trade off here that will depend on the specific dataset and analysis. As a rule of thumb, if a feature has more than 15% missing values, it may be better to remove the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived       11.447811\n",
      "pclass          7.295174\n",
      "sex            10.774411\n",
      "age            27.384961\n",
      "sibsp           9.764310\n",
      "parch           9.427609\n",
      "embarked       10.774411\n",
      "class           9.203143\n",
      "who            11.335578\n",
      "adult_male      9.988777\n",
      "deck           79.349046\n",
      "embark_town    11.335578\n",
      "alive           9.876543\n",
      "alone          12.121212\n",
      "target          0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_percent = df.isnull().mean() * 100\n",
    "print(missing_percent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smarter Imputation\n",
    "\n",
    "There are more advanced methods for imputation, such as using another machine learning models to predict the missing values. The idea here doesn't change, we have values that are missing, and we want to replace them with something that allows us to keep the value and use it in our analysis. The main thing that differs is that the simple imputation uses some pretty basic logic to replace the missing values, while the more advanced methods use more complex analysis to try to generate a better replacement for the missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "Pipelines are a very useful tool because they make our lives much easier when doing some of these data preparation steps. A pipeline is a series of steps that are executed in order. This is useful because it allows us to do a series of steps in a single command, and it also allows us to do the same steps on multiple datasets. We will create a pipeline that contains multiple steps, then instead of using a model's .fit() method to train the model on our processed data, we'll use the .fit() method on the pipeline to train the model on our data after all those steps we define are done. We basically can add many of the preparation steps to the pipeline, then use it just as we'd use a model, and the pipeline will automatically scale, impute, or do whatever else we've defined in the pipeline.\n",
    "\n",
    "![Pipeline](../images/pipe.png \"Pipeline\")\n",
    "\n",
    "### Sklearn Pipelines\n",
    "\n",
    "The pipeline tool that we use in sklearn to do this is the `Pipeline` tool. This tool allows us to define a series of steps, then use the pipeline as if it were a model. The creation and setup is fairly simple, we list the steps in a list of tuples, where the first element of the tuple is the name of the step, and the second element is the step itself. We then pass this list to the `Pipeline` tool, and we can use the pipeline as if it were a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch   target\n",
       "0       0.0     3.0  22.0    1.0    0.0   7.2500\n",
       "1       1.0     1.0   NaN    1.0    0.0  71.2833\n",
       "2       1.0     3.0  26.0    0.0    0.0   7.9250\n",
       "3       1.0     1.0  35.0    1.0    0.0  53.1000\n",
       "4       0.0     NaN  35.0    0.0    0.0   8.0500"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(numeric_features[\"target\"]).reshape(-1, 1)\n",
    "X = np.array(numeric_features.drop(columns=[\"target\"]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "numeric_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.3591033766387626\n",
      "Testing Score:  0.2752265648568497\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"reg\", LinearRegression())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"Training Score: \", pipe.score(X_train, y_train))\n",
    "print(\"Testing Score: \", pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Transformer Introduction\n",
    "\n",
    "One limitation of the pipeline tool is that it just does what it does to whatever you feed it. This is fine if you have a dataset that is all numerical, but if you have a dataset where we need to do encoding on some values and do scaling on some others, this isn't so simple. The `ColumnTransformer` tool is a tool that allows us to do different things to different columns. We can use this to do encoding on some columns and scaling on others, then pass this to the pipeline tool to do all of these steps in a single command.\n",
    "\n",
    "The column transformer can be a little annoying to construct syntax-wise, but the idea is very simple - it is a pipeline that can define different routes for different columns in our data. \n",
    "\n",
    "![Column Transformer](../images/column-transformer.png \"Column Transformer\")\n",
    "\n",
    "#### Sklearn Column Transformer\n",
    "\n",
    "Using the `ColumnTransformer` tool is very similar to using the `Pipeline` tool. We define a list of tuples, where the first element of the tuple is the name of the step, and the second element is the step itself. We then pass this list to the `ColumnTransformer` tool, and we can use the column transformer as if it were a model.\n",
    "\n",
    "<b>Note:</b> here we are using the column names, so I won't make the datasets into arrays. The pipeline, or the transformers inside of it, will do that for us automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch embarked  class    who  \\\n",
       "0       0.0     3.0    male  22.0    1.0    0.0        S  Third    man   \n",
       "1       1.0     1.0  female   NaN    1.0    0.0      NaN  First  woman   \n",
       "2       1.0     3.0  female  26.0    0.0    0.0        S  Third  woman   \n",
       "3       1.0     1.0  female  35.0    1.0    0.0        S  First    NaN   \n",
       "4       0.0     NaN    male  35.0    0.0    0.0        S  Third    man   \n",
       "\n",
       "  adult_male deck  embark_town alive  alone   target  \n",
       "0       True  NaN  Southampton    no    NaN   7.2500  \n",
       "1      False    C    Cherbourg   yes  False  71.2833  \n",
       "2      False  NaN          NaN   yes   True   7.9250  \n",
       "3      False    C  Southampton   NaN  False  53.1000  \n",
       "4       True  NaN  Southampton    no   True   8.0500  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"target\"]\n",
    "X = df.drop(columns=[\"target\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Preparation\n",
    "\n",
    "In this dataset we have a mix of numerical and categorical data. We will use the `ColumnTransformer` to do different things to different columns. We can define \"lanes\" of preparation that needs to take place, and then place each column into the correct lane. We need to:\n",
    "<ul>\n",
    "<li> Numerical data - impute missing values with the median, then scale the data. </li>\n",
    "<li> Categorical data - impute missing values with the most common category, then encode the data. </li>\n",
    "</ul>\n",
    "\n",
    "Each of these can be their own pipeline, they will do their process just like a normal pipeline, they'll just be applied to a subset of the original columns. The column transformer definition will have 3 parts - the name of the step, the step itself, and the columns that the step will be applied to.\n",
    "\n",
    "#### Column Transformer and Pipeline Structure\n",
    "\n",
    "The `ColumnTransformer` and `Pipeline` tools can be assembled into a nested structure that can be arbitrarily complex. In real world scenarios where data is being gathered from multiple sources, is relatively dirty, and widely varied, this can allow developers to build a long chain of data preparation steps that can handle almost any scenario. For our purposes, we can stick to a much simpler template that will handle virtually every scenario we may see:\n",
    "<ul>\n",
    "<li> A pipeline for numeric data that scales the data and imputes missing values. </li>\n",
    "<li> A pipeline for categorical data that imputes missing values and encodes the data. </li>\n",
    "<li> A column tranformer that combines the two and assigns each column to the appropriate pipeline. </li>\n",
    "<li> A final pipeline that combines the column transformer with a predictive model. This is what is fit to and used going forward. </li>\n",
    "<li> <i> If there's an odd case such as some numerical values need mean imputing, and others need median, we can mirror one of the original pipelines and add another row in the column transformer to split the data correctly. </i> </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('num', num_pipe, ['age', 'pclass', 'sibsp', 'parch']),\n",
    "    ('cat', cat_pipe, ['sex', 'class', 'embarked', 'who', 'deck', 'embark_town', 'alive', 'alone'])\n",
    "])\n",
    "\n",
    "final_pipe = Pipeline([\n",
    "    ('preprocessing', ct),\n",
    "    ('reg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Column Transformer\n",
    "\n",
    "Once the column transformer and its pipelines are created, they again work just like a normal model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.1988796116145607\n",
      "Testing Score:  -0.255962426979945\n"
     ]
    }
   ],
   "source": [
    "final_pipe.fit(X_train, y_train)\n",
    "print(\"Training Score: \", final_pipe.score(X_train, y_train))\n",
    "print(\"Testing Score: \", final_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pipelines in Practice\n",
    "\n",
    "In real applications, these pipelines make our lives far easier. Pipelines and column transformers can be stacked, mixed, and combined to make a set of steps that can do almost anything we desire. Most commonly, we may have different steps for different columns, and we have a few parallel pipelines that do different things to different columns. For example, we may do imputation differently on different sets of numerical columns and do encoding differently on different sets of categorical columns. Then we may combine all 4+ sets of steps using the column transformer. \n",
    "\n",
    "The main advantage of this is that we can do all of our data preparation in a single command, and we can use the same steps on multiple datasets. This is very useful in real world data analysis, where we may have data coming in batches, and we need to do the same steps on each batch before making a prediction. Imagine a regression model that predicts an interest rate to assign based on risk when someone applies for a mortgage - we will have applications flowing in all the time, and the process will need to scale the incomes, one-hot encode the property type, etc... on each one. Having all of those preparation steps \"built into\" the model using pipelines allows this to happen automatically, with no additional work needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Predict the price of the diamond using all the features in the dataset.\n",
    "\n",
    "<b>Note:</b> depending on your understanding of diamonds, some of the categories look like they may have some implicit order to them. Maybe capturing that in label encoding makes sense, maybe it doesn't. This would be a call that someone creating a model along with someone who knows diamonds would consider together, then test the results either way to evaluate. The simplest way to force order in label encoding is to use a dictionary to map the categories to numbers. \n",
    "\n",
    "```python\n",
    "label_encoding_dict = {\n",
    "    \"cut\": {\"Fair\": 1, \"Good\": 2, \"Very Good\": 3, \"Premium\": 4, \"Ideal\": 5},\n",
    "    \"color\": {\"J\": 1, \"I\": 2, \"H\": 3, \"G\": 4, \"F\": 5, \"E\": 6, \"D\": 7},\n",
    "    \"clarity\": {\"I1\": 1, \"SI2\": 2, \"SI1\": 3, \"VS2\": 4, \"VS1\": 5, \"VVS2\": 6, \"VVS1\": 7, \"IF\": 8}\n",
    "}\n",
    "\n",
    "df_dia.replace(label_encoding_dict, inplace=True)\n",
    "```\n",
    "In doing this, we would also think about the actual numerical values. If the range between them isn't one-by-one, we could change that. For example, maybe an \"ideal\" cut is better than a 5, we could score it a 7, so it would be \"more better\" than the other values. This is something that the diamond expert would need to weigh in on. When doing label encoding, you will want to scale these values as well, as they have a range that could be anything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44810</th>\n",
       "      <td>0.50</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5.09</td>\n",
       "      <td>5.14</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51461</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.68</td>\n",
       "      <td>5.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14312</th>\n",
       "      <td>1.01</td>\n",
       "      <td>Fair</td>\n",
       "      <td>D</td>\n",
       "      <td>VS2</td>\n",
       "      <td>59.1</td>\n",
       "      <td>68.0</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.44</td>\n",
       "      <td>3.84</td>\n",
       "      <td>5797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22587</th>\n",
       "      <td>1.25</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>VS2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.91</td>\n",
       "      <td>4.27</td>\n",
       "      <td>10640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36497</th>\n",
       "      <td>0.48</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.06</td>\n",
       "      <td>3.14</td>\n",
       "      <td>944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50106</th>\n",
       "      <td>0.62</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>54.5</td>\n",
       "      <td>5.46</td>\n",
       "      <td>5.48</td>\n",
       "      <td>3.39</td>\n",
       "      <td>2208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35592</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>62.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.72</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33020</th>\n",
       "      <td>0.33</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>61.2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.48</td>\n",
       "      <td>2.73</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>1.00</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>57.6</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6.47</td>\n",
       "      <td>6.44</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26872</th>\n",
       "      <td>2.31</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>I</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>8.50</td>\n",
       "      <td>5.29</td>\n",
       "      <td>16801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table     x     y     z  price\n",
       "44810   0.50  Very Good     G     VS1   61.0   59.0  5.09  5.14  3.12   1624\n",
       "51461   0.70    Premium     E     SI2   62.1   57.0  5.68  5.60  3.50   2376\n",
       "14312   1.01       Fair     D     VS2   59.1   68.0  6.56  6.44  3.84   5797\n",
       "22587   1.25    Premium     E     VS2   61.5   58.0  6.98  6.91  4.27  10640\n",
       "36497   0.48      Ideal     I     VS1   62.2   54.0  5.03  5.06  3.14    944\n",
       "50106   0.62      Ideal     E     VS2   62.0   54.5  5.46  5.48  3.39   2208\n",
       "35592   0.31      Ideal     H    VVS1   62.2   54.0  4.39  4.36  2.72    907\n",
       "33020   0.33      Ideal     E    VVS2   61.2   56.0  4.44  4.48  2.73    814\n",
       "4790    1.00       Good     E     SI1   57.6   65.0  6.47  6.44  3.72   3696\n",
       "26872   2.31  Very Good     I     SI1   62.5   55.0  8.43  8.50  5.29  16801"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dia = sns.load_dataset('diamonds')\n",
    "price = df_dia[\"price\"]\n",
    "df_dia = generateMissingValues(df_dia.drop(columns=[\"price\"]), 0.05)\n",
    "df_dia[\"price\"] = price\n",
    "df_dia.sample(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score:  0.8703625760895936\n",
      "Testing Score:  0.870026035204831\n"
     ]
    }
   ],
   "source": [
    "dia_numeric = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "dia_categorical = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "dia_ct = ColumnTransformer([\n",
    "    ('num', dia_numeric, ['carat', 'depth', 'table', 'x', 'y', 'z']),\n",
    "    ('cat', dia_categorical, ['cut', 'color', 'clarity'])\n",
    "])\n",
    "dia_pipe = Pipeline([\n",
    "    ('preprocessing', dia_ct),\n",
    "    ('reg', LinearRegression())\n",
    "])\n",
    "\n",
    "y = df_dia[\"price\"]\n",
    "X = df_dia.drop(columns=[\"price\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dia_pipe.fit(X_train, y_train)\n",
    "print(\"Training Score: \", dia_pipe.score(X_train, y_train))\n",
    "print(\"Testing Score: \", dia_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Exercise - For Funsies\n",
    "\n",
    "Now that you have a trained model, let's predict some diamond prices. For this we'll need a few steps:\n",
    "<ul>\n",
    "<li> Create some data to predict on. </li>\n",
    "    <ul>\n",
    "    <li> We need to create a table with the same columns as the training data, other than the price. </li>\n",
    "    <li> We need to create some rows of data to predict on, so make up some fake diamonds! Note that the categorical data needs to be from the classes in the original. </li>\n",
    "    <li> The fake generation can also be done randomly, or with something like np.random.choice() to select from the original data. This is a fun practice exercise itself! </li>\n",
    "    </ul>\n",
    "<li> Use the generateMissingValues function that is near the top of this notebook to generate some missing values in the fake data. </li>\n",
    "<li> Use the pipeline's predict function call to predict the price of the diamonds. </li>\n",
    "<li> Capture the predictions and add them to the incoming data from your price-free diamonds, as the predicted_price column. </li>\n",
    "</ul>\n",
    "\n",
    "<b>If you happen to get an implausible price, such as a negative price, that may well be a valid prediction - why do you think that happened?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.25</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>VS1</td>\n",
       "      <td>60.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.17</td>\n",
       "      <td>4.40</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VS2</td>\n",
       "      <td>59.5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.60</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.79</td>\n",
       "      <td>Premium</td>\n",
       "      <td>D</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.7</td>\n",
       "      <td>54.1</td>\n",
       "      <td>8.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.11</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>I1</td>\n",
       "      <td>62.1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>6.93</td>\n",
       "      <td>2.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.02</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.10</td>\n",
       "      <td>6.93</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat        cut color clarity  depth  table     x     y     z\n",
       "0   1.25      Ideal     H     VS1   60.3    NaN  5.17  4.40  2.69\n",
       "1   0.50    Premium     G     VS2   59.5   57.0   NaN  6.60  4.14\n",
       "2   0.79    Premium     D     VS2   62.7   54.1  8.47   NaN  3.63\n",
       "3   1.11       Good     J      I1   62.1   57.0  5.62  6.93  2.59\n",
       "4   1.02  Very Good     H    VVS2   62.3   57.0  6.10  6.93  4.55"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random data for each specified column\n",
    "df_generated = pd.DataFrame()\n",
    "df_generated['carat'] = np.random.choice(df_dia['carat'], size=10)\n",
    "df_generated['cut'] = np.random.choice(df_dia['cut'], size=10)\n",
    "df_generated['color'] = np.random.choice(df_dia['color'], size=10)\n",
    "df_generated['clarity'] = np.random.choice(df_dia['clarity'], size=10)\n",
    "df_generated['depth'] = np.random.choice(df_dia['depth'], size=10)\n",
    "df_generated['table'] = np.random.choice(df_dia['table'], size=10)\n",
    "df_generated['x'] = np.random.choice(df_dia['x'], size=10)\n",
    "df_generated['y'] = np.random.choice(df_dia['y'], size=10)\n",
    "df_generated['z'] = np.random.choice(df_dia['z'], size=10)\n",
    "df_generated = generateMissingValues(df_generated, 0.1)\n",
    "df_generated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>predicted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.25</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>VS1</td>\n",
       "      <td>60.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.17</td>\n",
       "      <td>4.40</td>\n",
       "      <td>2.69</td>\n",
       "      <td>6063.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VS2</td>\n",
       "      <td>59.5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.60</td>\n",
       "      <td>4.14</td>\n",
       "      <td>2941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.79</td>\n",
       "      <td>Premium</td>\n",
       "      <td>D</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.7</td>\n",
       "      <td>54.1</td>\n",
       "      <td>8.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.63</td>\n",
       "      <td>6262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.11</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>I1</td>\n",
       "      <td>62.1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.62</td>\n",
       "      <td>6.93</td>\n",
       "      <td>2.59</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.02</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.10</td>\n",
       "      <td>6.93</td>\n",
       "      <td>4.55</td>\n",
       "      <td>7066.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.51</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>J</td>\n",
       "      <td>VS2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Fair</td>\n",
       "      <td>G</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.79</td>\n",
       "      <td>7.52</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.57</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>61.7</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.10</td>\n",
       "      <td>5.25</td>\n",
       "      <td>2.96</td>\n",
       "      <td>3013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.40</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>I1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.74</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.05</td>\n",
       "      <td>-2077.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.12</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>59.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.56</td>\n",
       "      <td>6707.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat        cut color clarity  depth  table     x     y     z  \\\n",
       "0   1.25      Ideal     H     VS1   60.3    NaN  5.17  4.40  2.69   \n",
       "1   0.50    Premium     G     VS2   59.5   57.0   NaN  6.60  4.14   \n",
       "2   0.79    Premium     D     VS2   62.7   54.1  8.47   NaN  3.63   \n",
       "3   1.11       Good     J      I1   62.1   57.0  5.62  6.93  2.59   \n",
       "4   1.02  Very Good     H    VVS2   62.3   57.0  6.10  6.93  4.55   \n",
       "5   1.51      Ideal     J     VS2   61.5   56.0   NaN  7.90   NaN   \n",
       "6   0.72       Fair     G     SI1   63.5   57.0  4.79  7.52  3.85   \n",
       "7   0.57       Good     E    VVS1   61.7   58.0  5.10  5.25  2.96   \n",
       "8   0.40      Ideal     H      I1    NaN   56.0  6.74  4.20  4.05   \n",
       "9   1.12      Ideal     I    VVS2   59.3   58.0  6.34   NaN  3.56   \n",
       "\n",
       "   predicted_price  \n",
       "0           6063.0  \n",
       "1           2941.0  \n",
       "2           6262.0  \n",
       "3            497.0  \n",
       "4           7066.0  \n",
       "5           8014.0  \n",
       "6           2504.0  \n",
       "7           3013.0  \n",
       "8          -2077.0  \n",
       "9           6707.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_generated['predicted_price'] = dia_pipe.predict(df_generated)\n",
    "df_generated.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
