{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "teleFile = \"https://raw.githubusercontent.com/AkeemSemper/ML_for_Non_DS_Students/06a7b1408c3342b5a5d5d792742fda0760c9a476/data/tele.csv\"\n",
    "salaryFile = \"https://raw.githubusercontent.com/AkeemSemper/ML_for_Non_DS_Students/06a7b1408c3342b5a5d5d792742fda0760c9a476/data/salaries.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search and Model Improvements\n",
    "\n",
    "When creating a predictive model, there are several things that we can try to maximize the performance of the model, making it as useful as possible. Some of the common things we can do include:\n",
    "<ul>\n",
    "    <li>Selecting a model type that \"fits\" the data well.  We'll explore different models soon. </li>\n",
    "    <li>Get more or better data. This is often the most effective way to improve a model.</li>\n",
    "    <li>Improve the data. This can involve cleaning, normalizing, or transforming the data.</li>\n",
    "    <li>Improve the model by changing the hyperparameters that control it's creation - hyperparameter tuning. </li>\n",
    "</ul>\n",
    "\n",
    "Here, we'll focus on the last point - hyperparameter tuning. Specifically, we'll look at the tool that we normally use to conduct the hyperparameter tuning - a grid search.\n",
    "\n",
    "## Defining a Good Fit\n",
    "\n",
    "We will explore this concept more soon, but we can introduce a couple of very common terms we'll see when creating predictive models:\n",
    "<ul>\n",
    "    <li><b>Underfitting</b>: When a model is too simple to explain the variance in the data. It performs poorly on the training data and generalizes poorly to new data.</li>\n",
    "    <li><b>Overfitting</b>: When a model is too complex and learns the detail and noise in the training data to the extent that it negatively impacts the performance on new data.</li>\n",
    "</ul>\n",
    "\n",
    "Our goal here is a model that provides a good balance - we need it to learn enough to make accurate predictions, but not so much that it is bad at making predictions on new data.\n",
    "\n",
    "![Underfitting and Overfitting](../images/overfit_underfit.png \"Underfitting and Overfitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>radius error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>25.38</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>24.99</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>23.57</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>14.91</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>22.54</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   radius error  worst radius  worst perimeter  worst area  target  \n",
       "0        1.0950         25.38           184.60      2019.0       0  \n",
       "1        0.5435         24.99           158.80      1956.0       0  \n",
       "2        0.7456         23.57           152.50      1709.0       0  \n",
       "3        0.4956         14.91            98.87       567.7       0  \n",
       "4        0.7572         22.54           152.20      1575.0       0  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "df.drop([\"mean fractal dimension\", \"worst fractal dimension\", \"texture error\", \n",
    "         \"smoothness error\", \"symmetry error\", \"fractal dimension error\", \n",
    "         \"concavity error\", \"compactness error\", \"concave points error\",\n",
    "         \"perimeter error\", \"area error\", \"worst texture\", \"worst smoothness\",\n",
    "         \"worst symmetry\", \"worst compactness\", \"worst concavity\", \"worst concave points\"\n",
    "         ], axis=1, inplace=True)\n",
    "\n",
    "targ = pd.Series(data.target)\n",
    "\n",
    "df[\"target\"] = targ\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Hyperparameters are the parameters that are not learned by the model. They are set before the training process, normally as argument that we can specify when we create the object. Hyperparameters are important because they directly control the behavior of the training algorithm and have a significant impact on the performance of the model. These are different from the regular 'parameters', which is another term for the things that a model can learn - the weights/coefficients/slopes/etc. that are updated as the model is trained.\n",
    "\n",
    "![Hyperparameters](../images/hyperparameters.png \"Hyperparameters\")\n",
    "\n",
    "### Selecting Hyperparameters\n",
    "\n",
    "The hyperparameters can drastically impact the accuracy of a model, so one of the key things we can do is to try to select the best combination of hyperparameters for our scenario - a process called hyperparameter tuning. This process is simple at its core, we just need to test different combinations of hyperparameters and select the one that gives us the best results, as measured by whatever accuracy metric we are using.\n",
    "\n",
    "<b>Note:</b> you can ignore the details of what the hyperparameters in this image are for now, these ones come from neural networks, but the idea is identical for any model.\n",
    "\n",
    "![HP Tuning](../images/hp_tuning.webp \"HP Tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy:  0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "# Base model\n",
    "\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe_base = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"model\", LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe_base.fit(X_train, y_train)\n",
    "print(\"Base model accuracy: \", pipe_base.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Hyperparameters\n",
    "\n",
    "Logistic regression (and linear regression) actually have fewer hyperparameters than many other models, but we can still try a few and observe the results. Some that we can test in our grid search are:\n",
    "<ul>\n",
    "    <li><b>penalty</b>: The norm used in the penalization. We can use 'l1' or 'l2'.</li>\n",
    "    <li><b>C</b>: The inverse of regularization strength. Smaller values specify stronger regularization.</li>\n",
    "    <li><b>fit_intercept</b>: Whether to calculate the intercept for this model. If set to False, no intercept will be used in calculations.</li>\n",
    "</ul>\n",
    "\n",
    "<b>Note:</b> The details of what these are not super critical at this point, they are things that we'll look at more soon. Regularization is a technique that is used to prevent overfitting by limiting the size of the coefficients, it is common. We will look at regularization more soon, but we can manipulate the HP to see the impacts on our model. The fit_intercept parameter is just whether the model is allowed to have a \"b\" parameter in the equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test model accuracy:  0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "mod_test = LogisticRegression(penalty=\"l1\", C=0.1, solver=\"liblinear\", fit_intercept=False)\n",
    "\n",
    "pipe_test = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"model\", mod_test)\n",
    "])\n",
    "\n",
    "pipe_test.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test model accuracy: \", pipe_test.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "We can automate much of the boring work in testing hyperparameters by using a technique called grid search. This technique is simple: we just specify a list of values for each hyperparameter we want to test, and the grid search will test all possible combinations of these values. Like Magic!\n",
    "\n",
    "![Grid Search](../images/grid.png \"Grid Search\")\n",
    "\n",
    "#### Using a Grid Search\n",
    "\n",
    "We can use the GridSearchCV class to do this. We just need to specify the model we want to use, and the hyperparameters we want to test. The grid options are named using the convention nameOfObject__nameOfHyperparameter, with a double underscore separating the two. Where the nameOfObject is the name of that thing in the pipeline or column transformer that we provided, and the nameOfHyperparameter is the argument from that object. \n",
    "\n",
    "<b>Note:</b> the n_jobs=-1 argument tells the grid search to use all available cores on our machine to do the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'model__C': 206.913808111479, 'model__fit_intercept': True, 'model__penalty': 'l1', 'model__solver': 'liblinear'}\n",
      "Best score:  0.9670329670329669\n",
      "Test model accuracy:  0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"model__penalty\": [\"l1\", \"l2\"],\n",
    "    \"model__C\": np.logspace(-4, 4, 20),\n",
    "    \"model__solver\": [\"liblinear\", \"saga\"],\n",
    "    \"model__fit_intercept\": [True, False]\n",
    "}\n",
    "\n",
    "grid_pipe = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(grid_pipe, param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "best_params = grid.best_params_\n",
    "print(\"Best parameters: \", best_params)\n",
    "print(\"Best score: \", grid.best_score_)\n",
    "print(\"Test model accuracy: \", grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Results\n",
    "\n",
    "We can access some of the internal results of the grid search to see what the best hyperparameters were, and what the best score was. The attributes are listed on the sklearn documentation, and we can access them using the . notation. Note that these kinds of outputs from the sklearn library can be in a variety of formats, including dictionaries, lists, and numpy arrays - often with several potential layers of nesting. And those data structures may have varying levels of user friendliness. Getting the results out and using them can be annoying the first time, but they are the same each time going forward, so most of the code can be copied. Going one step further, this is one scenario where looking up code examples online can be very helpful. Someone has already written how to extract all these results into a nice format, we just need to adapt it to our specific scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__C': 206.913808111479,\n",
       " 'model__fit_intercept': True,\n",
       " 'model__penalty': 'l1',\n",
       " 'model__solver': 'liblinear'}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the Best Model\n",
    "\n",
    "Once the grid search is complete, we can use the best_estimator_ attribute to get the best model. We can then use this model to make predictions as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=206.913808111479, max_iter=10000,\n",
       "                                    penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LogisticRegression(C=206.913808111479, max_iter=10000,\n",
       "                                    penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=206.913808111479, max_iter=10000, penalty=&#x27;l1&#x27;,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=206.913808111479, max_iter=10000,\n",
       "                                    penalty='l1', solver='liblinear'))])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "When checking performance of a model, we always take a step to do the train-test split in the data, giving us one set of data used to create a model, and another set to test that model's accuracy on. This split in the data can have random variations though - what if the split randomly breaks up the data in a way that is not representative of the data as a whole? Or a way that puts a group of similar data all in the training set or the testing set. If we randomly break data into two groups, those groups aren't assured to both be similar and representative of the data as a whole. Usually they will be, but it varies - especially with small datasets.\n",
    "\n",
    "A solution to this is relatively simple, we just do the split multiple times, and average the results of all the trials. This is called cross validation. The most common form of cross validation is k-fold cross validation, where we split the data into k groups, and then use each group as the testing set in turn, with the rest of the data as the training set. We then average the results of all the trials to get a final accuracy score.\n",
    "\n",
    "![Cross Validation](../images/cross_val.jpg \"Cross Validation\")\n",
    "\n",
    "### Using Cross Validation\n",
    "\n",
    "In most cases, 5 to 10 folds are used for the cross validation calculations. The grid search will do cross validation as part of its process, but we can also call the cross_val_score function to do it directly, much like the score function. Be aware that this will perform each potential model in the grid search on each fold of the cross validation, so it can be a very computationally expensive process if the data is large or the model is complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "cv_params = {\n",
    "    \"model__penalty\": [\"l1\", \"l2\"],\n",
    "    \"model__C\": np.logspace(-4, 4, 20),\n",
    "    \"model__solver\": [\"liblinear\", \"saga\", \"lbfgs\", \"newton-cg\", \"sag\"],\n",
    "}\n",
    "\n",
    "cv_pipe = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "cv_grid = GridSearchCV(cv_pipe, cv_params, cv=30, n_jobs=-1)\n",
    "cv_grid.fit(X, y)\n",
    "\n",
    "cv_scores = cv_grid.cv_results_[\"mean_test_score\"]\n",
    "sns.histplot(cv_scores, kde=False, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation Score Function\n",
    "\n",
    "We can also use cross_val_score to get the cross validation score directly, anywhere that we'd use the score function to get the accuracy of a model. We can specify the number of folds to use, as well as the scoring metric to calculate. Note that we'll get back a list of scores, one for each fold, so if we want to summarize the results, we need to calculate the mean of the scores.\n",
    "\n",
    "This works for any model, classification or regression, as well as with any scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Scores:  [0.97142857 0.95774648 0.98630137 0.97222222 0.98630137 0.97222222\n",
      " 0.97297297 0.94444444 1.         0.97058824]\n",
      "Mean:  0.9734227887183818\n"
     ]
    }
   ],
   "source": [
    "vals = cross_val_score(best_model, X, y, cv=10, scoring=\"f1\")\n",
    "print(\"F1 Scores: \", vals)\n",
    "print(\"Mean: \", np.mean(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with Column Transformer\n",
    "\n",
    "We can also do a more complex and realistic example, with mixed feature necessitating a column transformer. \n",
    "\n",
    "#### Alternate Evaluation Metrics\n",
    "\n",
    "By default, the grid search will use the default evaluation metric for the model we are using. For logistic regression, this is the mean accuracy. We can specify a different metric if we want to. For example, if we are looking for a model that is less likely to miss things like fraud detection, we can use f1 (or almost anything we can imagine) as the key metric.\n",
    "\n",
    "The process of using the grid search does not change, but the model that is selected as the best will be based on whatever metric we specify instead of the regular accuracy. Note that if we are doing this with classification, we should also probably look at the accuracy and the confusion matrix as we did before - there's still risk to blindly trusting one metric, especially if we have data with an imbalance or if the impacts of false positives and false negatives are very different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data - Predict the Survival of Titanic Passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ct = sns.load_dataset(\"titanic\")\n",
    "df_ct.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search with Column Transformer Template\n",
    "\n",
    "The example below can be adapted to most of the problems you may encounter, with small changes. \n",
    "\n",
    "When using a column transformer or a large pipeline, it is common that we may have scenarios where we want to try different hyperparameters in things other than the final estimator (model). For example, we could use different imputation strategies and compare the results of mean vs median. In more complex examples later, we may have steps that do other types of data processing that we may want to test different hyperparameters for, such as removing the less useful features or simplifying the data to remove noise or speed processing. \n",
    "\n",
    "A grid search can be adapted to do the searching on any arguments in any step in our pipeline, we just need to specify the name of the step and the hyperparameter we want to test. \n",
    "\n",
    "#### Deeper Options in Grid Search\n",
    "\n",
    "The model is normally at the \"top level\" of the layers of pipelines and transformers in a more complex column transformer setup. To get to things that are embedded in more than one pipeline, we can just specify it by name with a double underscore between each object. For example, in the bottom row of the grid search we have options to change the imputer strategy for the numeric pipeline. To address that option, we have several layers in the addressing - first to look inside the column transformer \"ct\", then to look inside the numeric pipeline \"num\", and finally to look inside the imputer \"imputer_num\".\n",
    "\n",
    "This addressing scheme is somewhat annoying to use, but not that complex once you get used to it. We always need to refer to an option in the grid search by the name supplied in the pipeline or column transformer - if that option is inside more than one, then we need to work our way down through the layers, with a double underscore between each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'ct__num__imputer_num__strategy': 'mean', 'model__C': 0.012742749857031334, 'model__penalty': 'l1', 'model__solver': 'liblinear'}\n",
      "Best score:  1.0\n"
     ]
    }
   ],
   "source": [
    "y_ct = df_ct[\"survived\"]\n",
    "X_ct = df_ct.drop(\"survived\", axis=1)\n",
    "\n",
    "num_cols = X_ct.select_dtypes(include=np.number).columns\n",
    "cat_cols = X_ct.select_dtypes(include=\"object\").columns\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer_num\", SimpleImputer()),\n",
    "    (\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer_cat\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder())\n",
    "])\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "ct_params = {\n",
    "    \"model__penalty\": [\"l1\", \"l2\"],\n",
    "    \"model__C\": np.logspace(-4, 4, 20),\n",
    "    \"model__solver\": [\"liblinear\", \"saga\", \"lbfgs\", \"newton-cg\", \"sag\"],\n",
    "    \"ct__num__imputer_num__strategy\": [\"mean\", \"median\", \"most_frequent\"],\n",
    "}\n",
    "\n",
    "ct_pipe = Pipeline([\n",
    "    (\"ct\", ct),\n",
    "    (\"model\", LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "ct_grid = GridSearchCV(ct_pipe, ct_params, cv=5, n_jobs=-1, scoring=\"f1\")\n",
    "ct_grid.fit(X_ct, y_ct)\n",
    "\n",
    "print(\"Best parameters: \", ct_grid.best_params_)\n",
    "print(\"Best score: \", ct_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search in Practice\n",
    "\n",
    "The grid search is a simple way to find the best combination of hyperparameters from a list we define. In some cases though, we may not really know exactly what we should be trying in the first place. If we combine this with models that have lots of potential hyperparameter options, and datasets that are large and complex, we may end up with a huge number of combinations to try in our search for a good model. This can be computationally expensive, and time consuming.\n",
    "\n",
    "There are several grid search-like techniques that can help by working through different HP options like a grid search, but with some more smarts behind the logic, to try to find the best options more quickly. These include:\n",
    "<ul>\n",
    "    <li>RandomizedSearchCV</li>\n",
    "    <li>Bayesian Optimization</li>\n",
    "    <li>Genetic Algorithms</li>\n",
    "</ul>\n",
    "\n",
    "We will not cover these in this notebook, but they are things to think about if you keep going with machine learning. Each of these has its own strengths and weaknesses, but they all attempt to help find a good HP combinations without needing to work through massive numbers of trials. Outside of that, they are just like a grid search.\n",
    "\n",
    "It sounds kind of weird, but trial and error is a large part of machine learning, especially as things get more and more complex. We only have a rough idea of which model types, hyperparameters, and other options will work well for a given problem, and we don't actually know until we try it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# The halving ones require an option to be enabled. \n",
    "#from sklearn.model_selection import HalvingGridSearchCV\n",
    "#from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "\n",
    "IN_COLAB = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Create a Model with Grid Search\n",
    "\n",
    "Predict the target variable below. Use some of the hyperparameters that are available in the logistic regression model, from the class documentation page. Observe the best results, then try with some other accuracy metric outside of regular accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>retire</th>\n",
       "      <th>target</th>\n",
       "      <th>reside</th>\n",
       "      <th>custcat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>136.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region  tenure  age  marital  address  income  ed  employ  retire  target  \\\n",
       "0       2      13   44        1        9    64.0   4       5     0.0       0   \n",
       "1       3      11   33        1        7   136.0   5       5     0.0       0   \n",
       "2       3      68   52        1       24   116.0   1      29     0.0       1   \n",
       "3       2      33   33        0       12    33.0   2       0     0.0       1   \n",
       "4       2      23   30        1        9    30.0   1       2     0.0       0   \n",
       "\n",
       "   reside  custcat  \n",
       "0       2        1  \n",
       "1       6        4  \n",
       "2       2        3  \n",
       "3       1        1  \n",
       "4       4        3  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    #pass\n",
    "    !wget https://raw.githubusercontent.com/AkeemSemper/ML_for_Non_DS_Students/06a7b1408c3342b5a5d5d792742fda0760c9a476/data/tele.csv\n",
    "    df_class = pd.read_csv(\"tele.csv\")\n",
    "else:\n",
    "    df_class = pd.read_csv(\"../data/tele.csv\")\n",
    "    \n",
    "df_class.rename(columns={\"gender\":\"target\"}, inplace=True)\n",
    "df_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Actually... Some of Those Numbers May Be Categories..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Regression with Grid Search\n",
    "\n",
    "In this example try to predict the target. \n",
    "\n",
    "Use a SGDRegressor with a grid search to find the best hyperparameters. This model is a linear regression, but it uses gradient descent to find the best fit. Look up the documentation page for the model, grab some hyperparameters to test, and run some trials to see if you can find a good model. We will cover more on this model type soon. \n",
    "\n",
    "In processing the data, this dataset also has a few things that we can think about, they don't have one specific correct answer. For example, we'll have categories that have very uneven distributions. There are also categories with many different possible values, some very frequent and some occurring once. There are also columns that have data that is highly redundant with other columns. All of these things can be handled in a few different ways, and different solutions might be better for different problems. Try to think of a solution that can be logically supported - both in terms of what you know of predictive models, and of what you can think of from the real life problem. There aren't any specific skills or knowledge needed here beyond the basics, think about the goal and how each feature helps make that prediction. \n",
    "\n",
    "<b>Note:</b> all the dollar values are in USD now. The salary_currency column is their original currency. They are all converted to USD and can be directly compared in the target column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this type of model, it has more impactful hyperparameters\n",
    "# Check the sklearn docs for the hyperparameter list. \n",
    "# We'll explore a bit more what they mean in about a week. \n",
    "from sklearn.linear_model import SGDRegressor\n",
    "dummy_test_sgdr = SGDRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>target</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>USD</td>\n",
       "      <td>90000</td>\n",
       "      <td>AE</td>\n",
       "      <td>0</td>\n",
       "      <td>AE</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>USD</td>\n",
       "      <td>180500</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>USD</td>\n",
       "      <td>96200</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>USD</td>\n",
       "      <td>235000</td>\n",
       "      <td>AU</td>\n",
       "      <td>0</td>\n",
       "      <td>AU</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>USD</td>\n",
       "      <td>175000</td>\n",
       "      <td>AU</td>\n",
       "      <td>0</td>\n",
       "      <td>AU</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year experience_level employment_type                  job_title  \\\n",
       "0       2024               SE              FT                AI Engineer   \n",
       "1       2024               SE              FT  Machine Learning Engineer   \n",
       "2       2024               SE              FT  Machine Learning Engineer   \n",
       "3       2024               SE              FT  Machine Learning Engineer   \n",
       "4       2024               SE              FT  Machine Learning Engineer   \n",
       "\n",
       "  salary_currency  target employee_residence  remote_ratio company_location  \\\n",
       "0             USD   90000                 AE             0               AE   \n",
       "1             USD  180500                 US             0               US   \n",
       "2             USD   96200                 US             0               US   \n",
       "3             USD  235000                 AU             0               AU   \n",
       "4             USD  175000                 AU             0               AU   \n",
       "\n",
       "  company_size  \n",
       "0            L  \n",
       "1            M  \n",
       "2            M  \n",
       "3            M  \n",
       "4            M  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    !wget https://raw.githubusercontent.com/AkeemSemper/ML_for_Non_DS_Students/06a7b1408c3342b5a5d5d792742fda0760c9a476/data/salaries.csv\n",
    "    df_ex = pd.read_csv(\"salaries.csv\")\n",
    "    #pass\n",
    "else:\n",
    "    df_ex = pd.read_csv(\"../data/salaries.csv\")\n",
    "\n",
    "df_ex.rename(columns={\"salary_in_usd\": \"target\"}, inplace=True)\n",
    "df_ex.drop(\"salary\", axis=1, inplace=True)\n",
    "\n",
    "df_ex.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
